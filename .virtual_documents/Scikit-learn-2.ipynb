








!git clone https://github.com/ARIM-Academy/Advanced_Tutorial_1.git
%cd Advanced_Tutorial_1








#ライブラリ
import pandas as pd
import numpy as np 
import matplotlib.pyplot as plt
import seaborn as sns

import warnings
warnings.filterwarnings('ignore')





#データセットの読み込み
df = pd.read_csv('data/corrosin_data.csv', index_col=0)


#データセットの確認
df





#　記述子（特徴量）の選定および削除
df = df.drop(['Month'],axis = 1)
df








#腐食量（Corrosion）を目的変数として、それ以外を説明変数とする
X = df.iloc[0:, 0:16] # 説明変数
y = df.iloc[0:, -1]   # 目的変数





X





from sklearn.preprocessing import StandardScaler


# データの標準化
scaler = StandardScaler()
X_std = scaler.fit_transform(X)





#データセットの分割
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_std, y, 
                                                    test_size = 0.1,   # CV用データ分割
                                                    random_state = 42
                                                    )  





X_train











# 線形回帰モデル
from sklearn.linear_model import LinearRegression

#予測器の作成
model = LinearRegression()
model.fit(X_train, y_train)





#係数（重み）と切片
print('係数：',model.coef_)
print('切片：',model.intercept_)


#係数をPandasのSeries型に変換
coef = pd.Series(model.coef_, index = X.columns)
coef





# 回帰係数の可視化
fig, ax = plt.subplots(figsize=(6,6))

imp_coef = coef.sort_values()

ax.barh(imp_coef.index,
        imp_coef,
        color ='blue')

ax.grid()
plt.title('Regression coefficient') 

plt.show() 





#予測値
y_pred_train = model.predict(X_train)


# 訓練データの精度
r2_score = model.score(X_train, y_train)
print('訓練データ決定係数:{:.3f}'.format(r2_score))





#テストデータの予測値
y_pred_test = model.predict(X_test)


# テストデータの精度
r2_score = model.score(X_test, y_test)
print('テストデータ決定係数:{:.3f}'.format(r2_score))





fig, ax = plt.subplots(figsize=(6,6))

#データのプロット
ax.plot(y_train, y_pred_train, 'o', c = 'blue', label ='train')
ax.plot(y_test, y_pred_test, 'o', c = 'red', label ='test')

# 対角線のプロット
ax.plot([0, 3000], [0, 3000], 
        linestyle='--', 
        color ='gray')  

#グラフの修飾
ax.axis('square')
ax.set_xlabel('Observed',fontsize = 14)
ax.set_ylabel('Predicted',fontsize = 14)

ax.set_xlim(0,3000)
ax.set_ylim(0,3000)
ax.legend(fontsize = 14)
ax.grid()

plt.show()








# Lasso回帰モデル
from sklearn.linear_model import Lasso

#予測器の作成
model = Lasso()
model.fit(X_train, y_train)





#係数（重み）と切片
print('係数：',model.coef_)
print('切片：',model.intercept_)


coef = pd.Series(model.coef_, index = X.columns)
coef


# 回帰係数の可視化
fig, ax = plt.subplots(figsize=(6,6))

imp_coef = coef.sort_values()

ax.barh(imp_coef.index,
        imp_coef,
        color ='blue')

ax.grid()
plt.title('Lasso coefficient') 

plt.show() 





#予測値
y_pred_train = model.predict(X_train)


# 訓練データの精度
r2_score = model.score(X_train, y_train)
print('訓練データ決定係数:{:.3f}'.format(r2_score))





#テストデータの予測値
y_pred_test = model.predict(X_test)


# 訓練データの精度
r2_score = model.score(X_test, y_test)
print('テストデータ決定係数:{:.3f}'.format(r2_score))





fig, ax = plt.subplots(figsize=(6,6))

#データのプロット
ax.plot(y_train, y_pred_train, 'o', c = 'blue', label ='train')
ax.plot(y_test, y_pred_test, 'o', c = 'red', label ='test')

# 対角線のプロット
ax.plot([0, 3000], [0, 3000], 
        linestyle='--', 
        color ='gray')  

#グラフの修飾
ax.axis('square')
ax.set_xlabel('Observed',fontsize = 14)
ax.set_ylabel('Predicted',fontsize = 14)

ax.set_xlim(0,3000)
ax.set_ylim(0,3000)
ax.legend(fontsize = 14)
ax.grid()

plt.show()








#ランダムフォレスト回帰
from sklearn.ensemble import RandomForestRegressor

#予測器の作成
model = RandomForestRegressor(n_estimators=10)
model.fit(X_train, y_train)





coef = pd.Series(model.feature_importances_, index = X.columns)
coef


# 回帰係数の可視化
fig, ax = plt.subplots(figsize=(6,6))

imp_coef = coef.sort_values()

ax.barh(imp_coef.index,
        imp_coef,
        color ='blue')

ax.grid()
plt.title('Random Forrest Feature Importance') 
plt.show()





#予測値
y_pred_train = model.predict(X_train)


# 訓練データの精度
r2_score = model.score(X_train, y_train)
print('訓練データ決定係数:{:.3f}'.format(r2_score))





#テストデータの予測値
y_pred_test = model.predict(X_test)


# 訓練データの精度
r2_score = model.score(X_test, y_test)
print('テストデータ決定係数:{:.3f}'.format(r2_score))





fig, ax = plt.subplots(figsize=(6,6))

#データのプロット
ax.plot(y_train, y_pred_train, 'o', c = 'blue', label ='train')
ax.plot(y_test, y_pred_test, 'o', c = 'red', label ='test')

# 対角線のプロット
ax.plot([0, 3000], [0, 3000], 
        linestyle='--', 
        color ='gray')  

#グラフの修飾
ax.axis('square')
ax.set_xlabel('Observed',fontsize = 14)
ax.set_ylabel('Predicted',fontsize = 14)

ax.set_xlim(0,3000)
ax.set_ylim(0,3000)
ax.legend(fontsize = 14)
ax.grid()

plt.show()






